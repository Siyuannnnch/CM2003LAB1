{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Input, Activation, Dropout, BatchNormalization, Conv2DTranspose, Concatenate \n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from tensorflow.compat.v1 import reset_default_graph\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-net construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(input_layer, n_base, batchnorm = False):\n",
    "    output_layer = Conv2D(filters= n_base, kernel_size=(3,3), strides=(1,1), padding='same')(input_layer)\n",
    "    if batchnorm :\n",
    "        output_layer = BatchNormalization()(output_layer)\n",
    "    output_layer = Activation('relu')(output_layer)\n",
    "    output_layer = Conv2D(filters=n_base, kernel_size=(3,3), strides=(1,1), padding='same')(output_layer)\n",
    "    if batchnorm :\n",
    "        output_layer = BatchNormalization()(output_layer)\n",
    "    output_layer = Activation('relu')(output_layer)\n",
    "    return output_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_block(input_layer,n_base , batchnorm = False, dropout = False):\n",
    "    out = conv_block(input_layer, n_base, batchnorm = batchnorm)\n",
    "    out2 = MaxPooling2D(pool_size=(2,2))(out)\n",
    "    if dropout:\n",
    "        out2 = Dropout(0.2)(out2)\n",
    "    return out, out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_block(input_layer, layer2conc, n_base, batchnorm , dropout = False):\n",
    "    output_layer = Conv2DTranspose(filters = n_base,  kernel_size=(3,3), strides=(2, 2), padding=\"same\")(input_layer)\n",
    "    output_layer = Concatenate()([output_layer, layer2conc])\n",
    "    if dropout:\n",
    "        output_layer = Dropout(0.2)(output_layer)\n",
    "    output_layer = conv_block(output_layer, n_base, batchnorm = batchnorm)\n",
    "    return output_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unet(img_ch, img_width, img_height, n_base, dropout, batchnormal , binary = True, class_num = 2):\n",
    "    input_layer = Input(shape=(img_width, img_height, img_ch))\n",
    "    \n",
    "    #Encoder\n",
    "    e1, em1 = encoder_block(input_layer, n_base, batchnorm = batchnormal, dropout = dropout)\n",
    "    e2, em2 = encoder_block(em1, n_base*2, batchnorm = batchnormal, dropout = dropout)\n",
    "    e3, em3 = encoder_block(em2, n_base*4, batchnorm = batchnormal, dropout = dropout)\n",
    "    e4, em4 = encoder_block(em3, n_base*8, batchnorm = batchnormal, dropout = dropout)\n",
    "\n",
    "    #Bottleneck \n",
    "    bottleneck = conv_block(em4, n_base*16, batchnorm = batchnormal)\n",
    "\n",
    "    #Decoder\n",
    "    d_block1 = decoder_block(bottleneck, e4, n_base*8, batchnorm = batchnormal, dropout = dropout)\n",
    "    d_block2 = decoder_block(d_block1, e3, n_base*4, batchnorm = batchnormal, dropout = dropout)\n",
    "    d_block3 = decoder_block(d_block2, e2, n_base*2, batchnorm = batchnormal, dropout = dropout)\n",
    "    d_block4 = decoder_block(d_block3, e1, n_base, batchnorm = batchnormal, dropout = dropout)\n",
    "    \n",
    "    #Output\n",
    "    if binary:\n",
    "        out = Conv2D(filters=1, kernel_size=(3,3), strides=(1,1), padding='same', activation = 'sigmoid')(d_block4)\n",
    "    else:\n",
    "        out = Conv2D(filters=class_num, kernel_size=(3,3), strides=(1,1), padding='same', activation = 'sigmoid')(d_block4)\n",
    "        \n",
    "    clf = Model(inputs=input_layer, outputs=out)\n",
    "    clf.summary()\n",
    "    \n",
    "    return clf   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + 0.0001) / (K.sum(y_true_f) + K.sum(y_pred_f) + 0.0001)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1 - dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path, img_list, mask_list, state):\n",
    "    #Checking that img_list and mask_list are in the same order\n",
    "    mask_list2 = [mask.replace('_Tumor.png', '.png') for mask in mask_list]\n",
    "    if mask_list2 == img_list:\n",
    "        del mask_list2\n",
    "        pass\n",
    "    else :\n",
    "        print('Images and masks are not in the same order')\n",
    "    \n",
    "    #Initialising the final arrays\n",
    "    img_array = np.zeros((len(img_list), img_h, img_w), dtype = np.float32)\n",
    "    mask_array = np.zeros((len(mask_list), img_h, img_w), dtype = np.float32)\n",
    "    \n",
    "    ind = 0\n",
    "    for img_label, mask_label in zip(img_list, mask_list):\n",
    "        #Loading image\n",
    "        img = imread(data_path + 'Image/' + img_label, as_gray = True)\n",
    "        img = resize(img, (img_h, img_w), anti_aliasing = True).astype('float32')\n",
    "        img_array[ind] = (np.array(img)-np.min(np.array(img)))/(np.max(np.array(img))-np.min(np.array(img)))\n",
    "        #Loading mask\n",
    "        img = imread(data_path + 'Mask/' + mask_label, as_gray = True)\n",
    "        img = resize(img, (img_h, img_w), anti_aliasing = True).astype('float32')\n",
    "        mask_array[ind] = (np.array(img)-np.min(np.array(img)))/(np.max(np.array(img))-np.min(np.array(img)))\n",
    "        #Update counter\n",
    "        ind = ind + 1\n",
    "        print(state + ': ' + str(ind) + '/' + str(len(img_list)))\n",
    "    img_array = np.expand_dims(img_array, axis =3)\n",
    "    mask_array = np.expand_dims(mask_array, axis =3)\n",
    "    return img_array, mask_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/DL_course_data/Lab3/MRI/'\n",
    "img_list = os.listdir(path + 'Image/')[:6]\n",
    "shuffle(img_list)\n",
    "mask_list = [file.replace('.png', '_Tumor.png') for file in img_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def K_fold(x_list, y_list, path, K, current_index):\n",
    "    n = len(x_list)\n",
    "    x_test, y_test = load_data(path, \n",
    "                               x_list[current_index*int(n/K):(current_index+1)*int(n/K)], \n",
    "                               y_list[current_index*int(n/K):(current_index+1)*int(n/K)],\n",
    "                               'Test')\n",
    "    x_train, y_train = load_data(path, \n",
    "                                 x_list[:current_index*int(n/K)] + x_list[(current_index+1)*int(n/K):], \n",
    "                                 y_list[:current_index*int(n/K)] + y_list[(current_index+1)*int(n/K):],\n",
    "                                 'Train')\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 2 b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the get_autocontext_fold function\n",
    "def get_autocontext_fold(y_pred, f, images_per_fold, n_folds):\n",
    "    autocontext_val = y_pred[(f * images_per_fold):((f + 1) * images_per_fold), :, :, :]\n",
    "    print(autocontext_val.shape)\n",
    "    autocontext_train = np.concatenate((y_pred[:(f * images_per_fold), :, :, :], y_pred[((f + 1) * images_per_fold):, :, :, :]), axis = 0)\n",
    "    print(autocontext_train.shape)\n",
    "    #     if f != 0:\n",
    "#         autocontext_train[0:(f * images_per_fold)] = y_pred[0:(f * images_per_fold)]\n",
    "#     if f != (n_folds - 1):\n",
    "#         autocontext_train[((f + 1) * images_per_fold):]  = y_pred[((f + 1) * images_per_fold):]   \n",
    "    return autocontext_train, autocontext_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpu_devices = tf.config.experimental.list_physical_devices(device_type=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_CPU:0', device_type='XLA_CPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_GPU:0', device_type='XLA_GPU')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot set memory growth on non-GPU devices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-391ec6e79d78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_memory_growth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu_devices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/config.py\u001b[0m in \u001b[0;36mset_memory_growth\u001b[0;34m(device, enable)\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[0mRuntimeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRuntime\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0malready\u001b[0m \u001b[0minitialized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m   \"\"\"\n\u001b[0;32m--> 531\u001b[0;31m   \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_memory_growth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mset_memory_growth\u001b[0;34m(self, dev, enable)\u001b[0m\n\u001b[1;32m   1410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_type\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"GPU\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1412\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot set memory growth on non-GPU devices\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_memory_growth_map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0menable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot set memory growth on non-GPU devices"
     ]
    }
   ],
   "source": [
    " tf.config.experimental.set_memory_growth(gpu_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_h, img_w = 128, 128\n",
    "n_base = 8\n",
    "batchsize = 8\n",
    "LR = 1e-4\n",
    "n_epochs = 1\n",
    "T = 3 \n",
    "K1 = 3\n",
    "images_per_fold = int(len(img_list)/K1)\n",
    "\n",
    "for s in range(T):\n",
    "    \n",
    "    model_predictions = np.zeros((len(img_list), img_h, img_w, 1))\n",
    "#     !free -h | awk '/^Mem/ {print $3}\\'\n",
    "    \n",
    "    for f in range(K1):\n",
    "        \n",
    "        x_train, x_test, y_train, y_test = K_fold(img_list, mask_list, path, K1, f)\n",
    "        if s == 0:\n",
    "            autocontext_train = np.zeros_like(x_train) + 0.5\n",
    "            x_train = np.concatenate((x_train, autocontext_train), axis=-1)\n",
    "            del autocontext_train\n",
    "            \n",
    "            autocontext_val = np.zeros_like(x_test) + 0.5\n",
    "            x_test = np.concatenate((x_test, autocontext_val), axis=-1)\n",
    "            del autocontext_val\n",
    "        else:\n",
    "            ## load all the N outputs (training + validation sets) saved from all the K folds of step s-1 \n",
    "            y_pred = np.load('step' + str(s - 1) + '.npy')\n",
    "            autocontext_train, autocontext_val = get_autocontext_fold(y_pred, f,images_per_fold, K1)\n",
    "            del y_pred\n",
    "            # Concatenate image data and posterior probabilities:\n",
    "            x_train = np.concatenate((x_train, autocontext_train), axis=-1)\n",
    "            x_test = np.concatenate((x_test, autocontext_val), axis=-1)    \n",
    "            del autocontext_train, autocontext_val\n",
    "            \n",
    "        \n",
    "        #Training the network\n",
    "        print('ok')\n",
    "        clf = get_unet(2, img_w, img_h, n_base, True, True)  #ch need to 2\n",
    "        clf.compile(loss=[dice_coef_loss], optimizer = Adam(lr = LR), metrics=[dice_coef, Precision(), Recall()])\n",
    "        clf_hist = clf.fit(x_train, y_train, epochs = n_epochs, batch_size = batchsize, validation_data=(x_test, y_test))\n",
    "        \n",
    "        #Saving results\n",
    "        #Loss\n",
    "        plt.figure(figsize=(4, 4))\n",
    "        plt.title(\"Learning curve\")\n",
    "        plt.plot(clf_hist.history[\"loss\"], label=\"loss\")\n",
    "        plt.plot(clf_hist.history[\"val_loss\"], label=\"val_loss\")\n",
    "        xmin = np.argmin(clf_hist.history[\"val_loss\"])\n",
    "        ymin = np.min(clf_hist.history[\"val_loss\"])\n",
    "        plt.plot( xmin, ymin, marker=\"x\", color=\"r\", label=\"best model\")\n",
    "        plt.annotate('(' + str(xmin) + ', '+ str(round(ymin, 2)) + ')', xy = (xmin, ymin - 0.01),\n",
    "                     horizontalalignment = \"center\", verticalalignment = \"top\", color = \"red\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Loss Value\")\n",
    "        plt.legend();\n",
    "#         plt.savefig('2/Cycle '+str(s+1)+'/loss_cycle-'+str(s+1)+'_fold-'+ str(f+1) +'.png', dpi = 200)\n",
    "\n",
    "        #Accuracy\n",
    "        plt.figure(figsize=(4, 4))\n",
    "        plt.title(\"Accuracy\")\n",
    "        plt.plot(clf_hist.history[\"dice_coef\"], label=\"accuracy\")\n",
    "        plt.plot(clf_hist.history[\"val_dice_coef\"], label=\"val_accuracy\")\n",
    "        xmax = np.argmax(clf_hist.history[\"val_dice_coef\"])\n",
    "        ymax = np.max(clf_hist.history[\"val_dice_coef\"])\n",
    "        plt.plot( xmax, ymax, marker=\"x\", color=\"r\", label=\"best model\")\n",
    "        plt.annotate('(' + str(xmax) + ', '+ str(round(ymax,2)) + ')', xy = (xmax, ymax + 0.01),\n",
    "                     horizontalalignment = \"center\", verticalalignment = \"bottom\", color = \"red\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Accuracy Value\")\n",
    "        plt.legend();\n",
    "#         plt.savefig('2/Cycle '+str(s+1)+'/acc_cycle-'+str(s+1)+'_fold-'+ str(f+1) +'.png', dpi = 200)\n",
    "\n",
    "        #Precision\n",
    "        plt.figure(figsize=(4, 4))\n",
    "        plt.title(\"Precision\")\n",
    "        plt.plot(clf_hist.history['precision'], label=\"Precision\")\n",
    "        plt.plot(clf_hist.history[\"val_precision\"], label=\"val_precision\")\n",
    "        xmax = np.argmax(clf_hist.history[\"val_precision\"])\n",
    "        ymax = np.max(clf_hist.history[\"val_precision\"])\n",
    "        plt.plot( xmax, ymax, marker=\"x\", color=\"r\", label=\"best model\")\n",
    "        plt.annotate('(' + str(xmax) + ', '+ str(round(ymax,2)) + ')', xy = (xmax, ymax + 0.01),\n",
    "                     horizontalalignment = \"center\", verticalalignment = \"bottom\", color = \"red\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Accuracy Value\")\n",
    "        plt.legend();\n",
    "#         plt.savefig('2/Cycle '+str(s+1)+'/prec_cycle-'+str(s+1)+'_fold-'+ str(f+1) +'.png', dpi = 200)\n",
    "\n",
    "        # Recall\n",
    "        plt.figure(figsize=(4, 4))\n",
    "        plt.title(\"Recall\")\n",
    "        plt.plot(clf_hist.history['recall'], label=\"Recall\")\n",
    "        plt.plot(clf_hist.history['val_recall'], label=\"val_Recall\")\n",
    "        xmax = np.argmax(clf_hist.history['val_recall'])\n",
    "        ymax = np.max(clf_hist.history['val_recall'])\n",
    "        plt.plot( xmax, ymax, marker=\"x\", color=\"r\", label=\"best model\")\n",
    "        plt.annotate('(' + str(xmax) + ', '+ str(round(ymax,2)) + ')', xy = (xmax, ymax + 0.01),\n",
    "                     horizontalalignment = \"center\", verticalalignment = \"bottom\", color = \"red\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Accuracy Value\")\n",
    "        plt.legend();\n",
    "#         plt.savefig('2/Cycle '+str(s+1)+'/rec_cycle-'+str(s+1)+'_fold-'+ str(f+1) +'.png', dpi = 200)\n",
    "        \n",
    "        del xmin, xmax, ymin, ymax\n",
    "        \n",
    "        print('ok2')\n",
    "        model_predictions[(f*images_per_fold):((f+1)*images_per_fold)] = clf.predict(x_test, batch_size=1)\n",
    "        print('ok4')\n",
    "        \n",
    "        #Free memory\n",
    "        gc.collect()\n",
    "        del clf\n",
    "        del x_train\n",
    "        del y_train\n",
    "        del x_test\n",
    "        del y_test\n",
    "        clear_session()\n",
    "        reset_default_graph()\n",
    "        \n",
    "    np.save('step' + str(s) + '.npy', model_predictions)\n",
    "    del model_predictions\n",
    "#     !free -h | awk '/^Mem/ {print $3}\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!free -h | awk '/^Mem/ {print $3}\\'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
