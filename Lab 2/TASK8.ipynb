{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loader\n",
    "import os\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_labels(im_name, pat1, pat2):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    im_name : Str\n",
    "        The image file name.\n",
    "    pat1 : Str\n",
    "        A string pattern in the filename for 1st class, e.g \"AFF\"\n",
    "    pat2 : Str\n",
    "        A string pattern in the filename 2nd class, e.g, \"Nff\"\n",
    "    Returns\n",
    "    -------\n",
    "    Label : Numpy array        \n",
    "        Class label of the filename name based on its pattern.\n",
    "    '''\n",
    "    if pat1 in im_name:\n",
    "        label = np.array([0])\n",
    "    elif pat2 in im_name:\n",
    "        label = np.array([1])\n",
    "    return label\n",
    "\n",
    "\n",
    "def get_data(data_path, data_list, img_h, img_w):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_data_path : Str\n",
    "        Path to the data directory\n",
    "    train_list : List\n",
    "        A list containing the name of the images.\n",
    "    img_h : Int\n",
    "        image height to be resized to.\n",
    "    img_w : Int\n",
    "        image width to be resized to.    \n",
    "    Returns\n",
    "    -------\n",
    "    img_labels : Nested List\n",
    "        A nested list containing the loaded images along with their\n",
    "        correcponding labels.\n",
    "    \"\"\"\n",
    "    img_labels = []      \n",
    "    for item in enumerate(data_list):\n",
    "        img = imread(os.path.join(data_path, item[1]), as_gray = True) # \"as_grey\"\n",
    "        img = resize(img, (img_h, img_w), anti_aliasing = True).astype('float32')\n",
    "        img_labels.append([np.array(img), gen_labels(item[1], 'AFF', 'NFF')])\n",
    "       \n",
    "        if item[0] % 100 == 0:\n",
    "             print('Reading: {0}/{1}  of train images'.format(item[0], len(data_list)))\n",
    "             \n",
    "    shuffle(img_labels)\n",
    "    return img_labels\n",
    "\n",
    "\n",
    "def get_data_arrays(nested_list, img_h, img_w):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    nested_list : nested list\n",
    "        nested list of image arrays with corresponding class labels.\n",
    "    img_h : Int\n",
    "        Image height.\n",
    "    img_w : Int\n",
    "        Image width.\n",
    "    Returns\n",
    "    -------\n",
    "    img_arrays : Numpy array\n",
    "        4D Array with the size of (n_data,img_h,img_w, 1)\n",
    "    label_arrays : Numpy array\n",
    "        1D array with the size (n_data).\n",
    "    \"\"\"\n",
    "    img_arrays = np.zeros((len(nested_list), img_h, img_w), dtype = np.float32)\n",
    "    label_arrays = np.zeros((len(nested_list)), dtype = np.int32)\n",
    "    for ind in range(len(nested_list)):\n",
    "        img_arrays[ind] = nested_list[ind][0]\n",
    "        label_arrays[ind] = nested_list[ind][1]\n",
    "    img_arrays = np.expand_dims(img_arrays, axis =3)\n",
    "    return img_arrays, label_arrays\n",
    "\n",
    "\n",
    "def get_train_test_arrays(train_data_path, test_data_path, train_list,\n",
    "                          test_list, img_h, img_w):\n",
    "    \"\"\"\n",
    "    Get the directory to the train and test sets, the files names and\n",
    "    the size of the image and return the image and label arrays for\n",
    "    train and test sets.\n",
    "    \"\"\"\n",
    "   \n",
    "    train_data = get_data(train_data_path, train_list, img_h, img_w)\n",
    "    test_data = get_data(test_data_path, test_list, img_h, img_w)\n",
    "   \n",
    "    train_img, train_label =  get_data_arrays(train_data, img_h, img_w)\n",
    "    test_img, test_label = get_data_arrays(test_data, img_h, img_w)\n",
    "    del(train_data)\n",
    "    del(test_data)      \n",
    "    return train_img, test_img, train_label, test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading: 0/1072  of train images\n",
      "Reading: 100/1072  of train images\n",
      "Reading: 200/1072  of train images\n",
      "Reading: 300/1072  of train images\n",
      "Reading: 400/1072  of train images\n",
      "Reading: 500/1072  of train images\n",
      "Reading: 600/1072  of train images\n",
      "Reading: 700/1072  of train images\n",
      "Reading: 800/1072  of train images\n",
      "Reading: 900/1072  of train images\n",
      "Reading: 1000/1072  of train images\n",
      "Reading: 0/140  of train images\n",
      "Reading: 100/140  of train images\n"
     ]
    }
   ],
   "source": [
    "img_w, img_h = 128, 128 # Setting the width and heights of the images.\n",
    "data_path = '/DL_course_data/Lab1/Bone/' # Path to data root with two subdirs.\n",
    "train_data_path = os.path.join(data_path, 'train')\n",
    "test_data_path = os.path.join(data_path, 'test')\n",
    "train_list = os.listdir(train_data_path)\n",
    "test_list = os.listdir(test_data_path)\n",
    "x_train, x_test, y_train, y_test = get_train_test_arrays(\n",
    "     train_data_path, test_data_path,\n",
    "     train_list, test_list, img_h, img_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Flatten \n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Activation\n",
    "from tensorflow.keras.layers import Dropout "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 128, 128, 16)      160       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 16)      2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 64, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 64, 32)        4640      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 64, 64, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                131136    \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,060,017\n",
      "Trainable params: 1,060,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1072 samples, validate on 140 samples\n",
      "Epoch 1/100\n",
      "1072/1072 [==============================] - 4s 4ms/sample - loss: 0.6929 - binary_accuracy: 0.5774 - val_loss: 0.6931 - val_binary_accuracy: 0.5071\n",
      "Epoch 2/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.6911 - binary_accuracy: 0.5979 - val_loss: 0.6927 - val_binary_accuracy: 0.5071\n",
      "Epoch 3/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.6791 - binary_accuracy: 0.5979 - val_loss: 0.7070 - val_binary_accuracy: 0.5071\n",
      "Epoch 4/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.6795 - binary_accuracy: 0.5896 - val_loss: 0.7049 - val_binary_accuracy: 0.5071\n",
      "Epoch 5/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.6741 - binary_accuracy: 0.5924 - val_loss: 0.7086 - val_binary_accuracy: 0.5071\n",
      "Epoch 6/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.6731 - binary_accuracy: 0.5998 - val_loss: 0.7055 - val_binary_accuracy: 0.5071\n",
      "Epoch 7/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.6778 - binary_accuracy: 0.5933 - val_loss: 0.7001 - val_binary_accuracy: 0.5071\n",
      "Epoch 8/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.6769 - binary_accuracy: 0.5942 - val_loss: 0.7033 - val_binary_accuracy: 0.5071\n",
      "Epoch 9/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.6762 - binary_accuracy: 0.5858 - val_loss: 0.7003 - val_binary_accuracy: 0.5071\n",
      "Epoch 10/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.6723 - binary_accuracy: 0.5979 - val_loss: 0.7036 - val_binary_accuracy: 0.5071\n",
      "Epoch 11/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.6760 - binary_accuracy: 0.5905 - val_loss: 0.6981 - val_binary_accuracy: 0.5071\n",
      "Epoch 12/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.6692 - binary_accuracy: 0.5989 - val_loss: 0.7053 - val_binary_accuracy: 0.5071\n",
      "Epoch 13/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.6731 - binary_accuracy: 0.5951 - val_loss: 0.6975 - val_binary_accuracy: 0.5071\n",
      "Epoch 14/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.6694 - binary_accuracy: 0.5961 - val_loss: 0.7077 - val_binary_accuracy: 0.5071\n",
      "Epoch 15/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.6735 - binary_accuracy: 0.5942 - val_loss: 0.6956 - val_binary_accuracy: 0.5071\n",
      "Epoch 16/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.6704 - binary_accuracy: 0.5914 - val_loss: 0.7068 - val_binary_accuracy: 0.5071\n",
      "Epoch 17/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.6724 - binary_accuracy: 0.5905 - val_loss: 0.7029 - val_binary_accuracy: 0.5071\n",
      "Epoch 18/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.6721 - binary_accuracy: 0.5933 - val_loss: 0.6929 - val_binary_accuracy: 0.5071\n",
      "Epoch 19/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.6639 - binary_accuracy: 0.6035 - val_loss: 0.7118 - val_binary_accuracy: 0.5071\n",
      "Epoch 20/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.6612 - binary_accuracy: 0.5998 - val_loss: 0.6910 - val_binary_accuracy: 0.5143\n",
      "Epoch 21/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.6555 - binary_accuracy: 0.6082 - val_loss: 0.6702 - val_binary_accuracy: 0.5571\n",
      "Epoch 22/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.6423 - binary_accuracy: 0.6390 - val_loss: 0.6253 - val_binary_accuracy: 0.6857\n",
      "Epoch 23/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.5988 - binary_accuracy: 0.6838 - val_loss: 0.5345 - val_binary_accuracy: 0.7500\n",
      "Epoch 24/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.5258 - binary_accuracy: 0.7407 - val_loss: 0.4396 - val_binary_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.4916 - binary_accuracy: 0.7556 - val_loss: 0.4260 - val_binary_accuracy: 0.7643\n",
      "Epoch 26/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.4471 - binary_accuracy: 0.7910 - val_loss: 0.4254 - val_binary_accuracy: 0.7500\n",
      "Epoch 27/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.4431 - binary_accuracy: 0.7929 - val_loss: 0.3896 - val_binary_accuracy: 0.7929\n",
      "Epoch 28/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.4270 - binary_accuracy: 0.7929 - val_loss: 0.3688 - val_binary_accuracy: 0.7929\n",
      "Epoch 29/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.4030 - binary_accuracy: 0.8060 - val_loss: 0.4055 - val_binary_accuracy: 0.7786\n",
      "Epoch 30/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.4011 - binary_accuracy: 0.8013 - val_loss: 0.3847 - val_binary_accuracy: 0.7857\n",
      "Epoch 31/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.3894 - binary_accuracy: 0.8134 - val_loss: 0.3743 - val_binary_accuracy: 0.7929\n",
      "Epoch 32/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.3754 - binary_accuracy: 0.8218 - val_loss: 0.3508 - val_binary_accuracy: 0.7929\n",
      "Epoch 33/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.3717 - binary_accuracy: 0.8218 - val_loss: 0.3590 - val_binary_accuracy: 0.7929\n",
      "Epoch 34/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.3814 - binary_accuracy: 0.8237 - val_loss: 0.3670 - val_binary_accuracy: 0.7929\n",
      "Epoch 35/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.3577 - binary_accuracy: 0.8330 - val_loss: 0.3449 - val_binary_accuracy: 0.7929\n",
      "Epoch 36/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.3565 - binary_accuracy: 0.8321 - val_loss: 0.3478 - val_binary_accuracy: 0.7857\n",
      "Epoch 37/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.3416 - binary_accuracy: 0.8414 - val_loss: 0.3675 - val_binary_accuracy: 0.8000\n",
      "Epoch 38/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.3450 - binary_accuracy: 0.8349 - val_loss: 0.3390 - val_binary_accuracy: 0.7929\n",
      "Epoch 39/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.3412 - binary_accuracy: 0.8424 - val_loss: 0.3442 - val_binary_accuracy: 0.8071\n",
      "Epoch 40/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.3301 - binary_accuracy: 0.8442 - val_loss: 0.3645 - val_binary_accuracy: 0.8071\n",
      "Epoch 41/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.3282 - binary_accuracy: 0.8526 - val_loss: 0.3753 - val_binary_accuracy: 0.8000\n",
      "Epoch 42/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.3169 - binary_accuracy: 0.8489 - val_loss: 0.3401 - val_binary_accuracy: 0.8071\n",
      "Epoch 43/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.3267 - binary_accuracy: 0.8479 - val_loss: 0.3448 - val_binary_accuracy: 0.8071\n",
      "Epoch 44/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.3021 - binary_accuracy: 0.8591 - val_loss: 0.3346 - val_binary_accuracy: 0.8071\n",
      "Epoch 45/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.3144 - binary_accuracy: 0.8601 - val_loss: 0.3224 - val_binary_accuracy: 0.8143\n",
      "Epoch 46/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.3071 - binary_accuracy: 0.8545 - val_loss: 0.3294 - val_binary_accuracy: 0.8143\n",
      "Epoch 47/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.2920 - binary_accuracy: 0.8545 - val_loss: 0.3222 - val_binary_accuracy: 0.8286\n",
      "Epoch 48/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.2993 - binary_accuracy: 0.8563 - val_loss: 0.3195 - val_binary_accuracy: 0.8214\n",
      "Epoch 49/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.3011 - binary_accuracy: 0.8722 - val_loss: 0.3523 - val_binary_accuracy: 0.8071\n",
      "Epoch 50/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.2949 - binary_accuracy: 0.8563 - val_loss: 0.3289 - val_binary_accuracy: 0.8214\n",
      "Epoch 51/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.2794 - binary_accuracy: 0.8759 - val_loss: 0.3185 - val_binary_accuracy: 0.8357\n",
      "Epoch 52/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.2802 - binary_accuracy: 0.8647 - val_loss: 0.3322 - val_binary_accuracy: 0.8143\n",
      "Epoch 53/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.2851 - binary_accuracy: 0.8610 - val_loss: 0.3254 - val_binary_accuracy: 0.8286\n",
      "Epoch 54/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.2817 - binary_accuracy: 0.8750 - val_loss: 0.3206 - val_binary_accuracy: 0.8214\n",
      "Epoch 55/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.2863 - binary_accuracy: 0.8647 - val_loss: 0.3201 - val_binary_accuracy: 0.8214\n",
      "Epoch 56/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.2787 - binary_accuracy: 0.8685 - val_loss: 0.3157 - val_binary_accuracy: 0.8500\n",
      "Epoch 57/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.2716 - binary_accuracy: 0.8834 - val_loss: 0.3424 - val_binary_accuracy: 0.8143\n",
      "Epoch 58/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.2712 - binary_accuracy: 0.8713 - val_loss: 0.3456 - val_binary_accuracy: 0.8214\n",
      "Epoch 59/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.2589 - binary_accuracy: 0.8741 - val_loss: 0.3904 - val_binary_accuracy: 0.8000\n",
      "Epoch 60/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.2569 - binary_accuracy: 0.8741 - val_loss: 0.3018 - val_binary_accuracy: 0.8500\n",
      "Epoch 61/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.2688 - binary_accuracy: 0.8741 - val_loss: 0.3323 - val_binary_accuracy: 0.8286\n",
      "Epoch 62/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.2582 - binary_accuracy: 0.8890 - val_loss: 0.3279 - val_binary_accuracy: 0.8357\n",
      "Epoch 63/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.2536 - binary_accuracy: 0.8853 - val_loss: 0.3189 - val_binary_accuracy: 0.8286\n",
      "Epoch 64/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.2517 - binary_accuracy: 0.8778 - val_loss: 0.3239 - val_binary_accuracy: 0.8286\n",
      "Epoch 65/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.2431 - binary_accuracy: 0.8955 - val_loss: 0.3022 - val_binary_accuracy: 0.8500\n",
      "Epoch 66/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.2502 - binary_accuracy: 0.8862 - val_loss: 0.3310 - val_binary_accuracy: 0.8214\n",
      "Epoch 67/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.2516 - binary_accuracy: 0.8918 - val_loss: 0.3074 - val_binary_accuracy: 0.8429\n",
      "Epoch 68/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.2462 - binary_accuracy: 0.8890 - val_loss: 0.3213 - val_binary_accuracy: 0.8286\n",
      "Epoch 69/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.2417 - binary_accuracy: 0.8927 - val_loss: 0.3078 - val_binary_accuracy: 0.8286\n",
      "Epoch 70/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.2374 - binary_accuracy: 0.8918 - val_loss: 0.3278 - val_binary_accuracy: 0.8214\n",
      "Epoch 71/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.2274 - binary_accuracy: 0.8983 - val_loss: 0.3458 - val_binary_accuracy: 0.8214\n",
      "Epoch 72/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.2247 - binary_accuracy: 0.8993 - val_loss: 0.3165 - val_binary_accuracy: 0.8357\n",
      "Epoch 73/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.2258 - binary_accuracy: 0.9011 - val_loss: 0.3112 - val_binary_accuracy: 0.8429\n",
      "Epoch 74/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.2276 - binary_accuracy: 0.8937 - val_loss: 0.3212 - val_binary_accuracy: 0.8357\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.2259 - binary_accuracy: 0.9049 - val_loss: 0.3078 - val_binary_accuracy: 0.8357\n",
      "Epoch 76/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.2247 - binary_accuracy: 0.8965 - val_loss: 0.5571 - val_binary_accuracy: 0.8000\n",
      "Epoch 77/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.2254 - binary_accuracy: 0.9021 - val_loss: 0.3411 - val_binary_accuracy: 0.8214\n",
      "Epoch 78/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.2139 - binary_accuracy: 0.8955 - val_loss: 0.3267 - val_binary_accuracy: 0.8357\n",
      "Epoch 79/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.2193 - binary_accuracy: 0.9039 - val_loss: 0.3294 - val_binary_accuracy: 0.8214\n",
      "Epoch 80/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.2036 - binary_accuracy: 0.9170 - val_loss: 0.3268 - val_binary_accuracy: 0.8357\n",
      "Epoch 81/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.1975 - binary_accuracy: 0.9058 - val_loss: 0.3120 - val_binary_accuracy: 0.8357\n",
      "Epoch 82/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.1953 - binary_accuracy: 0.9207 - val_loss: 0.4159 - val_binary_accuracy: 0.8286\n",
      "Epoch 83/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.2021 - binary_accuracy: 0.9132 - val_loss: 0.3378 - val_binary_accuracy: 0.8429\n",
      "Epoch 84/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.2014 - binary_accuracy: 0.9114 - val_loss: 0.3163 - val_binary_accuracy: 0.8357\n",
      "Epoch 85/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.1815 - binary_accuracy: 0.9160 - val_loss: 0.3368 - val_binary_accuracy: 0.8286\n",
      "Epoch 86/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.1887 - binary_accuracy: 0.9207 - val_loss: 0.3815 - val_binary_accuracy: 0.8429\n",
      "Epoch 87/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.2066 - binary_accuracy: 0.9114 - val_loss: 0.3183 - val_binary_accuracy: 0.8357\n",
      "Epoch 88/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.1841 - binary_accuracy: 0.9179 - val_loss: 0.3342 - val_binary_accuracy: 0.8500\n",
      "Epoch 89/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.1793 - binary_accuracy: 0.9254 - val_loss: 0.3782 - val_binary_accuracy: 0.8357\n",
      "Epoch 90/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.1845 - binary_accuracy: 0.9207 - val_loss: 0.3210 - val_binary_accuracy: 0.8429\n",
      "Epoch 91/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.1871 - binary_accuracy: 0.9132 - val_loss: 0.2792 - val_binary_accuracy: 0.8357\n",
      "Epoch 92/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.1847 - binary_accuracy: 0.9216 - val_loss: 0.3516 - val_binary_accuracy: 0.8500\n",
      "Epoch 93/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.1710 - binary_accuracy: 0.9282 - val_loss: 0.2972 - val_binary_accuracy: 0.8357\n",
      "Epoch 94/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.1688 - binary_accuracy: 0.9319 - val_loss: 0.3406 - val_binary_accuracy: 0.8500\n",
      "Epoch 95/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.1655 - binary_accuracy: 0.9375 - val_loss: 0.3750 - val_binary_accuracy: 0.8357\n",
      "Epoch 96/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.1797 - binary_accuracy: 0.9282 - val_loss: 0.3863 - val_binary_accuracy: 0.8429\n",
      "Epoch 97/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.1729 - binary_accuracy: 0.9272 - val_loss: 0.3775 - val_binary_accuracy: 0.8429\n",
      "Epoch 98/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.1565 - binary_accuracy: 0.9272 - val_loss: 0.2970 - val_binary_accuracy: 0.8429\n",
      "Epoch 99/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.1756 - binary_accuracy: 0.9235 - val_loss: 0.3424 - val_binary_accuracy: 0.8214\n",
      "Epoch 100/100\n",
      "1072/1072 [==============================] - 2s 2ms/sample - loss: 0.1628 - binary_accuracy: 0.9300 - val_loss: 0.3324 - val_binary_accuracy: 0.8429\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the minimum var_loss is 0.2792458317375609\n",
      "the Best epoch nr is 90\n",
      "the maximum var_accuracy is 0.85\n",
      "the maximum train_accuracy is 0.9375\n",
      "the Best epoch nr is 55\n"
     ]
    }
   ],
   "source": [
    "def model(img_ch, img_width, img_height, n_base):\n",
    " \n",
    "     model = Sequential()\n",
    " \n",
    "     model.add(Conv2D(filters=n_base, input_shape=(img_width, img_height, img_ch),\n",
    "                 kernel_size=(3,3), activation='relu', strides=(1,1), padding='same'))\n",
    "     model.add(Conv2D(filters=n_base, input_shape=(img_width, img_height, img_ch),\n",
    "                 kernel_size=(3,3), activation='relu', strides=(1,1), padding='same'))\n",
    "     model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "     model.add(Conv2D(filters= n_base *2, kernel_size=(3,3), activation='relu', strides=(1,1), padding='same'))\n",
    "     model.add(Conv2D(filters= n_base *2, kernel_size=(3,3), activation='relu', strides=(1,1), padding='same'))\n",
    "     model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "        \n",
    "     model.add(Conv2D(filters= n_base *4, kernel_size=(3,3), activation='relu', strides=(1,1), padding='same'))\n",
    "     model.add(Conv2D(filters= n_base *4, kernel_size=(3,3), activation='relu', strides=(1,1), padding='same'))\n",
    "     model.add(Conv2D(filters= n_base *4, kernel_size=(3,3), activation='relu', strides=(1,1), padding='same'))\n",
    "     model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "        \n",
    "     model.add(Conv2D(filters= n_base *8, kernel_size=(3,3), activation='relu', strides=(1,1), padding='same'))\n",
    "     model.add(Conv2D(filters= n_base *8, kernel_size=(3,3), activation='relu', strides=(1,1), padding='same'))\n",
    "     model.add(Conv2D(filters= n_base *8, kernel_size=(3,3), activation='relu', strides=(1,1), padding='same'))\n",
    "     model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "        \n",
    "     model.add(Conv2D(filters= n_base *8, kernel_size=(3,3), activation='relu', strides=(1,1), padding='same'))\n",
    "     model.add(Conv2D(filters= n_base *8, kernel_size=(3,3), activation='relu', strides=(1,1), padding='same'))\n",
    "     model.add(Conv2D(filters= n_base *8, kernel_size=(3,3), activation='relu', strides=(1,1), padding='same'))\n",
    "     model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "        \n",
    "     model.add(Flatten())\n",
    "    \n",
    "     model.add(Dense(64))\n",
    "     model.add(Activation('relu'))\n",
    "     model.add(Dropout(0.2))\n",
    "        \n",
    "     model.add(Dense(64))\n",
    "     model.add(Activation('relu'))\n",
    "     model.add(Dropout(0.2))   \n",
    "    \n",
    "     model.add(Dense(64))\n",
    "     model.add(Activation('relu'))\n",
    "     model.add(Dropout(0.2))\n",
    "        \n",
    "     model.add(Dense(1))\n",
    "     model.add(Activation('sigmoid'))\n",
    "     model.summary() \n",
    "     return model\n",
    "firstlayer = 16\n",
    "batchsize = 8\n",
    "n_epochs = 100   # 20\n",
    "learningrate = 0.00001   #0.00001\n",
    "\n",
    "clf =  model(1,img_w, img_h,firstlayer)\n",
    "\n",
    "clf.compile(loss='binary_crossentropy',\n",
    "              optimizer = Adam(lr = learningrate),\n",
    "              metrics=['binary_accuracy'])\n",
    "clf_hist = clf.fit(x_train, y_train, epochs = n_epochs, batch_size = batchsize, validation_data = (x_test,y_test))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.title(\"Learning curve\")\n",
    "plt.plot(clf_hist.history[\"loss\"], label=\"loss\")\n",
    "plt.plot(clf_hist.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot( np.argmin(clf_hist.history[\"val_loss\"]),\n",
    "     np.min(clf_hist.history[\"val_loss\"]),\n",
    "     marker=\"x\", color=\"r\", label=\"best model\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss Value\")\n",
    "plt.legend();\n",
    "plt.show()\n",
    "print('the minimum var_loss is', np.min(clf_hist.history[\"val_loss\"]))\n",
    "print('the Best epoch nr is', np.argmin(clf_hist.history[\"val_loss\"]))\n",
    "\n",
    "\n",
    "#Accuracy\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.title(\"Accuracy\")\n",
    "plt.plot(clf_hist.history[\"binary_accuracy\"], label=\"accuracy\")\n",
    "plt.plot(clf_hist.history[\"val_binary_accuracy\"], label=\"val_accuracy\")\n",
    "xmax = np.argmax(clf_hist.history[\"val_binary_accuracy\"])\n",
    "ymax = np.max(clf_hist.history[\"val_binary_accuracy\"])\n",
    "plt.plot( xmax, ymax, marker=\"x\", color=\"r\", label=\"best model\")\n",
    "plt.annotate('(' + str(xmax) + ', '+ str(round(ymax,2)) + ')', xy = (xmax, ymax + 0.01),\n",
    "             horizontalalignment = \"center\", verticalalignment = \"bottom\", color = \"red\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss Value\")\n",
    "plt.legend();\n",
    "print('the maximum var_accuracy is', np.max(clf_hist.history[\"val_binary_accuracy\"]))\n",
    "print('the maximum train_accuracy is', np.max(clf_hist.history[\"binary_accuracy\"]))\n",
    "print('the Best epoch nr is', xmax)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1072, 128, 128, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140, 128, 128, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
